{"version":3,"sources":["webpack:///webpack/universalModuleDefinition","webpack:///webpack/bootstrap bbccd000cc558d5c0a7d","webpack:///./tinylex.ts"],"names":[],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD,O;ACVA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;;AAGA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAK;AACL;AACA;;AAEA;AACA;AACA;AACA,mCAA2B,0BAA0B,EAAE;AACvD,yCAAiC,eAAe;AAChD;AACA;AACA;;AAEA;AACA,8DAAsD,+DAA+D;;AAErH;AACA;;AAEA;AACA;;;;;;;;;;;;;;;;;;;;;;AChDA,IAAU;AACD,aAGH;AAJgB;;;AAcpB,qBAAwB,MAAgB;YAAE,8EAAuB;;;;AAC3D,aAAM,QAAO,QAAM;AACnB,aAAO,SAAQ,SAAM;AACrB,aAAQ,UAAI;AACZ,aAAQ,UAAK;AACb,aAAS,WAAG,UAAU;AAAS,mBAAO;AAAC;AACvC,aAAa,eAAU,QAAQ,WACrC;AAEO;;;;gCAAY;AACb,iBAAS,WAAK;AACZ,mBACR;AAKI;;;;AACI,mBAAK,KAAQ,WAAQ,KAAM,MACnC;AAKG;;;;AACE,gBAAK,KAAQ,QAAE;AAChB,sBAAM,IAAS,MACjB;AAAC;AAED,mBAAM,CAAK,KAAO,QAAG;AACnB,oBAAW,QAAO,KAAQ;AACvB,oBAAO,OAAE;AACV,wBAAY,SAAO,KAAS,SAAM,OAAM,KAAY;AACjD,wBAAQ,QAAE;AAAO,+BAAQ;AAC9B;AACF;AAAC;AACD,gBAAc,WAAU,CAAM,OAAQ;AACtC,gBAAc,WAAO,KAAS,SAAS,UAAO;AACxC,mBAAS,YACjB;AAKQ;;;;AACE,gDACV;AAKa;;;;AAGX,mBAAM,CAAK,KAAQ,QAAO,UAAQ,KAAQ,UAAO,KAAM,MAAO;AAC5D,oBAAW,QAAO,KAAM,MAAM,MAAK,KAAS;AAC5C,oBAAS,MAAO,KAAO,OAEjB;;AAJyD,oCAIrC,KAAa,aAAO;;oBAAnC;oBAAQ;;AAEhB,oBAAO,OAAE;AACN,yBAAW,aAAQ;AACpB,wBAAC,CAAK,KAAa,aAAK,MAAO,OAAS,QAAE;AACrC,+BACR;AACF;AAAM,uBAAE;AACF,yBAAa,aACnB;AACF;AAAC;AAEE,gBAAK,KAAQ,QAAQ,QAAE;AAClB,uBAAK,KAAQ,QACrB;AACF;AAKI;;;;;;AACI;AACA;AAAQ;AACN,8BAAM,MAAO,QAAO,OAAE,CAAK,MAAO,UAAQ,MAGpD;AAJiB;;AADR;AAUT;;aAAO,OAAU;;AAAW,mBAAK,KAAQ;AAKrB;;;qCAAc;AAChC,gBAAS,MAAO,KAAO,OAAO;AAE1B,iBAAC,IAAK,IAAI,GAAG,IAAM,KAAK,KAAG;AAC7B,oBAAU,OAAO,KAAO,OAAG;AAC3B,oBAAW,QAAO,KAAG,GAAK,KAAO;AAC9B,oBAAO,OAAE;AAAO,2BAAC,CAAK,MAAS;AACpC;AAAC;AACK,mBAAC,CAAK,MACd;AAKoB;;;qCAAW,MAAc,OAAe;AAC1D,gBAAY,SAAK;AACjB,gBAAe,YAAO,KAAG;AAEtB,gBAAC,OAAgB,cAAc,UAAE;AAC5B,uBAAK,KAAC,CAAU,WAAO,MAAG,MAAU,OAAM,MAAK,KAAM,MAAK;AAC5D,qBAAQ,WAAS,MAAG,GAC1B;AAEI,uBAAK,OAAgB,cAAc,UAAE;AACvC,oBAAW,QAAQ,MAAW;AACxB,uBAAK,KAAC,CAAM,MAAoB,qBAAS;AAC3C,qBAAQ,WAAS,MAAG,GAC1B;AAEI,aANI,UAMC,OAAgB,cAAgB,YAAE;AACzC,oBAAS,MAAY,UAAK,KAAK,MAAO,OAAQ,QAAQ;AACtD,oBAAU,OAAQ,MAAG,GAAO;AACxB,qBAAQ,WAAI,OAAU,QACtB,WAAK,KAAM,MAAK,KAAI,IAAM,SAAW,OAC3C;AAEI,aAPI,MAOA,IAAU,aAAS,MAAE;AACvB,qBAAQ,WAAS,MAAG,GAAO;AAEzB,uBACR;AAAC;AAEG,iBAAQ,UAAO,KAAQ,QAAO,OAAO,OAAW;AAG9C,mBAAO,OAAS,SAAO,OAC/B;AAKoB;;;qCAAc;AAC1B,oBAAK,KAAgB;AACzB,qBAAY;AAAE,0BAAM,IAAS,MAAK,KAAa,aAAQ;AACvD,qBAAa;AAAM,yBAAQ,WAAM;AAAM;AACvC;AAAa,yBAAc,cAE/B;;AAKqB;;;sCAAc;AACjC,gBAAU,OAAQ,MAAM,MAAE,GAAI;AAC1B,iBAAQ,QAAK,KAAC,CAAK,KAAoB,qBAAQ;AAC/C,iBAAQ,WACd;AAKoB;;;qCAAc;AAC1B,mBAAC,eAAiB,KAEtB,2DAAU,MAAQ,QAAO,QAAM,KAAM,MAAE,GAC3C;AAKmB;;;;AACjB,gBAAW,QAAO,KAAM,MAAM,MAAE,GAAM,KAAS,SAAM,MAAM;AAC3D,gBAAS,MAAQ,MAAM,MAAO,SAAK,GAAO,SAAI;AACvC,mBAAQ,MAAO,eACxB;AACD","file":"./tinylex.js","sourcesContent":["(function webpackUniversalModuleDefinition(root, factory) {\n\tif(typeof exports === 'object' && typeof module === 'object')\n\t\tmodule.exports = factory();\n\telse if(typeof define === 'function' && define.amd)\n\t\tdefine([], factory);\n\telse {\n\t\tvar a = factory();\n\t\tfor(var i in a) (typeof exports === 'object' ? exports : root)[i] = a[i];\n\t}\n})(typeof self !== 'undefined' ? self : this, function() {\nreturn \n\n\n// WEBPACK FOOTER //\n// webpack/universalModuleDefinition"," \t// The module cache\n \tvar installedModules = {};\n\n \t// The require function\n \tfunction __webpack_require__(moduleId) {\n\n \t\t// Check if module is in cache\n \t\tif(installedModules[moduleId]) {\n \t\t\treturn installedModules[moduleId].exports;\n \t\t}\n \t\t// Create a new module (and put it into the cache)\n \t\tvar module = installedModules[moduleId] = {\n \t\t\ti: moduleId,\n \t\t\tl: false,\n \t\t\texports: {}\n \t\t};\n\n \t\t// Execute the module function\n \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n \t\t// Flag the module as loaded\n \t\tmodule.l = true;\n\n \t\t// Return the exports of the module\n \t\treturn module.exports;\n \t}\n\n\n \t// expose the modules object (__webpack_modules__)\n \t__webpack_require__.m = modules;\n\n \t// expose the module cache\n \t__webpack_require__.c = installedModules;\n\n \t// define getter function for harmony exports\n \t__webpack_require__.d = function(exports, name, getter) {\n \t\tif(!__webpack_require__.o(exports, name)) {\n \t\t\tObject.defineProperty(exports, name, {\n \t\t\t\tconfigurable: false,\n \t\t\t\tenumerable: true,\n \t\t\t\tget: getter\n \t\t\t});\n \t\t}\n \t};\n\n \t// getDefaultExport function for compatibility with non-harmony modules\n \t__webpack_require__.n = function(module) {\n \t\tvar getter = module && module.__esModule ?\n \t\t\tfunction getDefault() { return module['default']; } :\n \t\t\tfunction getModuleExports() { return module; };\n \t\t__webpack_require__.d(getter, 'a', getter);\n \t\treturn getter;\n \t};\n\n \t// Object.prototype.hasOwnProperty.call\n \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n\n \t// __webpack_public_path__\n \t__webpack_require__.p = \"\";\n\n \t// Load entry module and return exports\n \treturn __webpack_require__(__webpack_require__.s = 0);\n\n\n\n// WEBPACK FOOTER //\n// webpack/bootstrap bbccd000cc558d5c0a7d","export type Match = RegExpExecArray\nexport type Token = [string, string]\nexport type RuleFn = (match: Match, tokens: Token[], chunk: string) => number|void\nexport type Rule = [RegExp, string|number|RuleFn]|[RegExp]\nexport type RuleMatch = [Rule, Match]\nexport type Ruleset = Rule[]\nexport type OnToken = (token: Token, match: Match) => Token|string\nexport type ErrorAction = 'throw'|'tokenize'|'ignore'\n\nexport interface Options {\n  onError: ErrorAction\n}\n\nconst opts: Options = {\n  onError: 'tokenize'\n}\n\nexport class TinyLex {\n  private _code: string\n  private _rules: Rule[]\n  private _options: Options\n  private _cursor: number\n  private _tokens: Token[]\n  private _onToken: OnToken\n  private _lastMatch: Match\n  private _errorAction: ErrorAction\n\n  constructor(code: string, rules: Ruleset, options: Options = opts) {\n    this._code = code || ''\n    this._rules = rules || []\n    this._cursor = 0\n    this._tokens = []\n    this._onToken = (token) => { return token }\n    this._errorAction = options.onError || 'tokenize'\n  }\n\n  onToken(fn: OnToken): this {\n    this._onToken = fn\n    return this\n  }\n\n  /**\n   * Return true if the lexer is consumed.\n   */\n  done(): boolean {\n    return this._cursor >= this._code.length\n  }\n\n  /**\n   * Return a single lexer match or eof.\n   */\n  lex(): Token|string {\n    if (this.done()) {\n      throw new Error('lexer is consumed')\n    }\n\n    while(!this.done()) {\n      const token = this._scan()\n      if (token) {\n        const _token = this._onToken(token, this._lastMatch)\n        if (_token) { return _token }\n      }\n    }\n    const eofToken: Token = ['EOF', 'EOF']\n    const newToken = this._onToken(eofToken, null)\n    return newToken || eofToken\n  }\n\n  /**\n   * Consume the lexer and return a list of its tokens.\n   */\n  tokenize(): (Token|string)[] {\n    return [...this]\n  }\n\n  /**\n   * Lexer scan method.\n   */\n  private _scan(): Token {\n    // Process input while there aren't any tokens and we\n    // haven't reached the end.\n    while(!this._tokens.length && this._cursor < this._code.length) {\n      const chunk = this._code.slice(this._cursor)\n      const len = this._rules.length\n\n      const [rule, match] = this._testRuleSet(chunk)\n\n      if (match) {\n        this._lastMatch = match\n        if (!this._handleMatch(rule, match, chunk)) {\n          return null\n        }\n      } else {\n        this._handleError(chunk)\n      }\n    }\n\n    if (this._tokens.length) {\n      return this._tokens.pop()\n    }\n  }\n\n  /**\n   * Javascript iterator method.\n   */\n  next() {\n    return {\n      next: () => ({\n        done: this.done(), value: !this.done() && this.lex()\n      })\n    }\n  }\n\n  /**\n   * Javascript iterable protocol.\n   */\n  [Symbol.iterator]() { return this.next() }\n\n  /**\n   * Iterate the ruleset and return a match if found.\n   */\n  private _testRuleSet(chunk: string): RuleMatch {\n    const len = this._rules.length\n    // Process rules in order to find a match.\n    for (let i = 0; i < len; i++) {\n      const rule = this._rules[i]\n      const match = rule[0].exec(chunk)\n      if (match) { return [rule, match] }\n    }\n    return [null, null]\n  }\n\n  /**\n   * Handle a lexer match.\n   */\n  private _handleMatch(rule: Rule, match: Match, chunk: string): boolean {\n    const tokens = []\n    const specifier = rule[1]\n\n    if (typeof specifier === 'string') {\n      tokens.push([specifier, match[1] != null ? match[1] : match[0]])\n      this._cursor += match[0].length\n    }\n\n    else if (typeof specifier === 'number') {\n      const value = match[specifier]\n      tokens.push([value.toLocaleUpperCase(), value])\n      this._cursor += match[0].length\n    }\n\n    else if (typeof specifier === 'function') {\n      const num = specifier.call(this, match, tokens, chunk)\n      const size = match[0].length\n      this._cursor += typeof num === 'number'\n        ? (Math.floor(Math.abs(num)) || size) : size\n    }\n\n    else if (specifier == null) {\n      this._cursor += match[0].length\n      // A token was not added.\n      return false\n    }\n\n    this._tokens = this._tokens.concat(tokens.reverse())\n\n    // A token may have been added.\n    return tokens.length ? true : false\n  }\n\n  /**\n   * Handle a lex error (no rule found).\n   */\n  private _handleError(chunk: string) {\n    switch(this._errorAction) {\n      case 'throw': throw new Error(this._getErrorStr(chunk))\n      case 'ignore': this._cursor += 1; break\n      default: this._tokenizeChar(chunk)\n    }\n  }\n\n  /**\n   * Tokenize the next single character in the current chunk.\n   */\n  private _tokenizeChar(chunk: string): void {\n    const char = chunk.slice(0, 1)\n    this._tokens.push([char.toLocaleUpperCase(), char])\n    this._cursor += 1\n  }\n\n  /**\n   * Get a lex error message.\n   */\n  private _getErrorStr(chunk: string): string {\n    return `lex error:${this._lineAndCol()}`\n    + `\\n  match not found for chunk:`\n    + ` \"${chunk.replace(/\\s+/g, ' ').slice(0, 32)}...\"`\n  }\n\n  /**\n   * Return the current line and column based on the lexer progress.\n   */\n  private _lineAndCol(): string {\n    const lines = this._code.slice(0, this._cursor).split('\\n')\n    const col = lines[lines.length - 1].length + 1\n    return `${lines.length}:${col}`\n  }\n}\n\n\n\n// WEBPACK FOOTER //\n// ./tinylex.ts"],"sourceRoot":""}