{"version":3,"sources":["webpack:///webpack/universalModuleDefinition","webpack:///webpack/bootstrap e093f4d8ec8071680935","webpack:///./tinylex.ts"],"names":[],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD,O;ACVA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;;AAGA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAK;AACL;AACA;;AAEA;AACA;AACA;AACA,mCAA2B,0BAA0B,EAAE;AACvD,yCAAiC,eAAe;AAChD;AACA;AACA;;AAEA;AACA,8DAAsD,+DAA+D;;AAErH;AACA;;AAEA;AACA;;;;;;;;;;;;;;;;;;;;;;AChDA,IAAU;AACD,aAGH;AAJgB;;;AAcpB,qBAAwB,MAAgB;YAAE,8EAAuB;;;;AAC5D,YAAE,CAAM,MAAQ,QAAS,QAAE;AAC5B,kBAAM,IAAS,MAEjB;AAAC;AACG,aAAM,QAAO;AACb,aAAO,SAAQ;AACf,aAAO,SAAI;AACX,aAAQ,UAAK;AACb,aAAS,WAAQ;AAAS,mBAAM;AAAC;AACjC,aAAa,eAAU,QAC7B;AAEO;;;;gCAAY;AACb,iBAAS,WAAK;AACZ,mBACR;AAKI;;;;AACI,mBAAC,CAAK,KAAM,SAAQ,KAAO,UAAQ,KAAM,MACjD;AAKG;;;;AACE,gBAAK,KAAQ,QAAE;AAChB,sBAAM,IAAS,MACjB;AAAC;AAED,mBAAM,CAAK,KAAO,QAAG;AACnB,oBAAW,QAAO,KAAQ;AACvB,oBAAO,OAAE;AACV,wBAAc,YAAO,KAAS,SAAM,OAAM,KAAY;AACnD,wBAAU,WAAE;AAAO,+BAAU;AAAC;AAC3B,2BACR;AACF;AAAC;AACD,gBAAc,WAAU,CAAM,OAAQ;AACtC,gBAAc,WAAO,KAAS,SAAS,UAAO;AAC1C,iBAAW;AACT,mBAAS,YACjB;AAKQ;;;;AACE,gDACV;AAKa;;;;AAGX,mBAAM,CAAK,KAAQ,QAAO,UAAQ,KAAO,SAAO,KAAM,MAAO;AAC3D,oBAAW,QAAO,KAAM,MAAM,MAAK,KAAQ;AAC3C,oBAAS,MAAO,KAAO,OAEjB;;AAJwD,oCAIpC,KAAa,aAAO;;oBAAnC;oBAAQ;;AAEhB,oBAAO,OAAE;AACN,yBAAW,aAAQ;AACpB,wBAAC,CAAK,KAAa,aAAK,MAAO,OAAS,QAAE;AACrC,+BACR;AACF;AAAM,uBAAE;AACF,yBAAa,aACnB;AACF;AAAC;AAEE,gBAAK,KAAQ,QAAQ,QAAE;AAClB,uBAAK,KAAQ,QACrB;AACF;AAKI;;;;;;AACI;AACA;AAAQ;AACN,8BAAM,MAAO,QAAO,OAAE,CAAK,MAAO,UAAQ,MAGpD;AAJiB;;AADR;AAUT;;aAAO,OAAU;;AAAW,mBAAK,KAAQ;AAKrB;;;qCAAc;AAChC,gBAAS,MAAO,KAAO,OAAO;AAE1B,iBAAC,IAAK,IAAI,GAAG,IAAM,KAAK,KAAG;AAC7B,oBAAU,OAAO,KAAO,OAAG;AAC3B,oBAAW,QAAO,KAAG,GAAK,KAAO;AAC9B,oBAAO,OAAE;AAAO,2BAAC,CAAK,MAAS;AACpC;AAAC;AACK,mBAAC,CAAK,MACd;AAKoB;;;qCAAW,MAAc,OAAe;AAC1D,gBAAY,SAAK;AACjB,gBAAe,YAAO,KAAG;AAEtB,gBAAC,OAAgB,cAAc,UAAE;AAC5B,uBAAK,KAAC,CAAU,WAAO,MAAG,MAAU,OAAM,MAAK,KAAM,MAAK;AAC5D,qBAAO,UAAS,MAAG,GACzB;AAEI,uBAAK,OAAgB,cAAc,UAAE;AACvC,oBAAW,QAAQ,MAAW;AACxB,uBAAK,KAAC,CAAM,MAAoB,qBAAS;AAC3C,qBAAO,UAAS,MAAG,GACzB;AAEI,aANI,UAMC,OAAgB,cAAgB,YAAE;AACzC,oBAAS,MAAY,UAAM,OAAQ,QAAQ;AAC3C,oBAAU,OAAQ,MAAG,GAAO;AACxB,qBAAO,UAAI,OAAU,QACrB,WAAK,KAAM,MAAK,KAAI,IAAM,SAAW,OAC3C;AAEI,aAPI,MAOA,IAAU,aAAS,MAAE;AACvB,qBAAO,UAAS,MAAG,GAAO;AAExB,uBACR;AAAC;AAEG,iBAAQ,UAAO,KAAQ,QAAO,OAAO,OAAW;AAG9C,mBAAO,OAAS,SAAO,OAC/B;AAKoB;;;qCAAc;AAC1B,oBAAK,KAAgB;AACzB,qBAAY;AAAE,0BAAM,IAAS,MAAK,KAAa,aAAQ;AACvD,qBAAe;AAAM,yBAAc,cAAQ;AAAM;AACjD;AAAa,yBAAO,UAAM;AAE9B;;AAKqB;;;sCAAc;AACjC,gBAAU,OAAQ,MAAM,MAAE,GAAI;AAC1B,iBAAQ,QAAK,KAAC,CAAK,KAAoB,qBAAQ;AAC/C,iBAAO,UACb;AAKoB;;;qCAAc;AAC1B,mBAAC,eAAiB,KAEtB,2DAAU,MAAQ,QAAO,QAAM,KAAM,MAAE,GAC3C;AAKmB;;;;AACjB,gBAAW,QAAO,KAAM,MAAM,MAAE,GAAM,KAAQ,QAAM,MAAM;AAC1D,gBAAS,MAAQ,MAAM,MAAO,SAAK,GAAO,SAAI;AACvC,mBAAQ,MAAO,eACxB;AAKgB;;;;AACV,iBAAM,QAAO,KAAO,SAAO,KAAQ,UAAO,KAAS,WAC/C,KAAW,aACrB;AACD","file":"./tinylex.js","sourcesContent":["(function webpackUniversalModuleDefinition(root, factory) {\n\tif(typeof exports === 'object' && typeof module === 'object')\n\t\tmodule.exports = factory();\n\telse if(typeof define === 'function' && define.amd)\n\t\tdefine([], factory);\n\telse {\n\t\tvar a = factory();\n\t\tfor(var i in a) (typeof exports === 'object' ? exports : root)[i] = a[i];\n\t}\n})(typeof self !== 'undefined' ? self : this, function() {\nreturn \n\n\n// WEBPACK FOOTER //\n// webpack/universalModuleDefinition"," \t// The module cache\n \tvar installedModules = {};\n\n \t// The require function\n \tfunction __webpack_require__(moduleId) {\n\n \t\t// Check if module is in cache\n \t\tif(installedModules[moduleId]) {\n \t\t\treturn installedModules[moduleId].exports;\n \t\t}\n \t\t// Create a new module (and put it into the cache)\n \t\tvar module = installedModules[moduleId] = {\n \t\t\ti: moduleId,\n \t\t\tl: false,\n \t\t\texports: {}\n \t\t};\n\n \t\t// Execute the module function\n \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n \t\t// Flag the module as loaded\n \t\tmodule.l = true;\n\n \t\t// Return the exports of the module\n \t\treturn module.exports;\n \t}\n\n\n \t// expose the modules object (__webpack_modules__)\n \t__webpack_require__.m = modules;\n\n \t// expose the module cache\n \t__webpack_require__.c = installedModules;\n\n \t// define getter function for harmony exports\n \t__webpack_require__.d = function(exports, name, getter) {\n \t\tif(!__webpack_require__.o(exports, name)) {\n \t\t\tObject.defineProperty(exports, name, {\n \t\t\t\tconfigurable: false,\n \t\t\t\tenumerable: true,\n \t\t\t\tget: getter\n \t\t\t});\n \t\t}\n \t};\n\n \t// getDefaultExport function for compatibility with non-harmony modules\n \t__webpack_require__.n = function(module) {\n \t\tvar getter = module && module.__esModule ?\n \t\t\tfunction getDefault() { return module['default']; } :\n \t\t\tfunction getModuleExports() { return module; };\n \t\t__webpack_require__.d(getter, 'a', getter);\n \t\treturn getter;\n \t};\n\n \t// Object.prototype.hasOwnProperty.call\n \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n\n \t// __webpack_public_path__\n \t__webpack_require__.p = \"\";\n\n \t// Load entry module and return exports\n \treturn __webpack_require__(__webpack_require__.s = 0);\n\n\n\n// WEBPACK FOOTER //\n// webpack/bootstrap e093f4d8ec8071680935","export type Match = RegExpExecArray\nexport type Token = [string, string]\nexport type RuleFn = (match: Match, tokens: Token[], chunk: string) => number|void\nexport type Rule = [RegExp, string|number|RuleFn]|[RegExp]\nexport type RuleMatch = [Rule, Match]\nexport type Ruleset = Rule[]\nexport type OnToken = (token: Token, match: Match) => Token|string\nexport type ErrorAction = 'throw'|'tokenize'|'ignore'\n\nexport interface Options {\n  onError: ErrorAction\n}\n\nconst opts: Options = {\n  onError: 'tokenize'\n}\n\nexport class TinyLex {\n  private _code: string\n  private _rules: Rule[]\n  private _options: Options\n  private _start: number\n  private _tokens: Token[]\n  private _onToken: OnToken\n  private _lastMatch: Match\n  private _errorAction: ErrorAction\n\n  constructor(code: string, rules: Ruleset, options: Options = opts) {\n    if (!(Array.isArray(rules))) {\n      throw new Error(\n        'Invalid ruleset: rules must be a non-zero length array')\n    }\n    this._code = code\n    this._rules = rules\n    this._start = 0\n    this._tokens = []\n    this._onToken = () => { return null }\n    this._errorAction = options.onError\n  }\n\n  onToken(fn: OnToken): this {\n    this._onToken = fn\n    return this\n  }\n\n  /**\n   * Return true if the lexer is consumed.\n   */\n  done(): boolean {\n    return !this._code || this._start >= this._code.length\n  }\n\n  /**\n   * Return a single lexer match or eof.\n   */\n  lex(): Token|string {\n    if (this.done()) {\n      throw new Error('lexer is consumed')\n    }\n\n    while(!this.done()) {\n      const token = this._scan()\n      if (token) {\n        const newToken = this._onToken(token, this._lastMatch)\n        if (newToken) { return newToken }\n        return token\n      }\n    }\n    const eofToken: Token = ['EOF', 'EOF']\n    const newToken = this._onToken(eofToken, null)\n    this._destroy()\n    return newToken || eofToken\n  }\n\n  /**\n   * Consume the lexer and return a list of its tokens.\n   */\n  tokenize(): (Token|string)[] {\n    return [...this]\n  }\n\n  /**\n   * Lexer scan method.\n   */\n  private _scan(): Token {\n    // Process input while there aren't any tokens and we\n    // haven't reached the end.\n    while(!this._tokens.length && this._start < this._code.length) {\n      const chunk = this._code.slice(this._start)\n      const len = this._rules.length\n\n      const [rule, match] = this._testRuleSet(chunk)\n\n      if (match) {\n        this._lastMatch = match\n        if (!this._handleMatch(rule, match, chunk)) {\n          return null\n        }\n      } else {\n        this._handleError(chunk)\n      }\n    }\n\n    if (this._tokens.length) {\n      return this._tokens.pop()\n    }\n  }\n\n  /**\n   * Javascript iterator method.\n   */\n  next() {\n    return {\n      next: () => ({\n        done: this.done(), value: !this.done() && this.lex()\n      })\n    }\n  }\n\n  /**\n   * Javascript iterable protocol.\n   */\n  [Symbol.iterator]() { return this.next() }\n\n  /**\n   * Iterate the ruleset and return a match if found.\n   */\n  private _testRuleSet(chunk: string): RuleMatch {\n    const len = this._rules.length\n    // Process rules in order to find a match.\n    for (let i = 0; i < len; i++) {\n      const rule = this._rules[i]\n      const match = rule[0].exec(chunk)\n      if (match) { return [rule, match] }\n    }\n    return [null, null]\n  }\n\n  /**\n   * Handle a lexer match.\n   */\n  private _handleMatch(rule: Rule, match: Match, chunk: string): boolean {\n    const tokens = []\n    const specifier = rule[1]\n\n    if (typeof specifier === 'string') {\n      tokens.push([specifier, match[1] != null ? match[1] : match[0]])\n      this._start += match[0].length\n    }\n\n    else if (typeof specifier === 'number') {\n      const value = match[specifier]\n      tokens.push([value.toLocaleUpperCase(), value])\n      this._start += match[0].length\n    }\n\n    else if (typeof specifier === 'function') {\n      const num = specifier(match, tokens, chunk)\n      const size = match[0].length\n      this._start += typeof num === 'number'\n        ? (Math.floor(Math.abs(num)) || size) : size\n    }\n\n    else if (specifier == null) {\n      this._start += match[0].length\n      // A token was not added.\n      return false\n    }\n\n    this._tokens = this._tokens.concat(tokens.reverse())\n\n    // A token may have been added.\n    return tokens.length ? true : false\n  }\n\n  /**\n   * Handle a lex error (no rule found).\n   */\n  private _handleError(chunk: string) {\n    switch(this._errorAction) {\n      case 'throw': throw new Error(this._getErrorStr(chunk))\n      case 'tokenize': this._tokenizeChar(chunk); break\n      default: this._start += 1; break\n    }\n  }\n\n  /**\n   * Tokenize the next single character in the current chunk.\n   */\n  private _tokenizeChar(chunk: string): void {\n    const char = chunk.slice(0, 1)\n    this._tokens.push([char.toLocaleUpperCase(), char])\n    this._start += 1\n  }\n\n  /**\n   * Get a lex error message.\n   */\n  private _getErrorStr(chunk: string): string {\n    return `lex error:${this._lineAndCol()}`\n    + `\\n  match not found for chunk:`\n    + ` \"${chunk.replace(/\\s+/g, ' ').slice(0, 32)}...\"`\n  }\n\n  /**\n   * Return the current line and column based on the lexer progress.\n   */\n  private _lineAndCol(): string {\n    const lines = this._code.slice(0, this._start).split('\\n')\n    const col = lines[lines.length - 1].length + 1\n    return `${lines.length}:${col}`\n  }\n\n  /**\n   * Clear member variable referneces.\n   */\n  private _destroy(): void {\n    this._code = this._rules = this._tokens = this._onToken\n      = this._lastMatch = null\n  }\n}\n\n\n\n// WEBPACK FOOTER //\n// ./tinylex.ts"],"sourceRoot":""}