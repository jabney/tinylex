{"version":3,"sources":["webpack:///webpack/universalModuleDefinition","webpack:///webpack/bootstrap 8e785c4a7410adb20419","webpack:///./tinylex.ts"],"names":[],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD,O;ACVA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;;AAGA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAK;AACL;AACA;;AAEA;AACA;AACA;AACA,mCAA2B,0BAA0B,EAAE;AACvD,yCAAiC,eAAe;AAChD;AACA;AACA;;AAEA;AACA,8DAAsD,+DAA+D;;AAErH;AACA;;AAEA;AACA;;;;;;;;;;;;;;;;;;;;;;AChDA,IAAM,OAAgB;AACpB,aAAS;AADW,CAAtB;;IAIM,O,WAAA,O;AAUJ,qBAAY,IAAZ,EAA0B,KAA1B,EAAiE;AAAA,YAAvB,OAAuB,uEAAJ,IAAI;;AAAA;;AAC/D,aAAK,KAAL,GAAa,QAAQ,EAArB;AACA,aAAK,MAAL,GAAc,SAAS,EAAvB;AACA,aAAK,OAAL,GAAe,CAAf;AACA,aAAK,OAAL,GAAe,EAAf;AACA,aAAK,QAAL,GAAgB,UAAC,KAAD,EAAU;AAAG,mBAAO,KAAP;AAAc,SAA3C;AACA,aAAK,YAAL,GAAoB,QAAQ,OAAR,IAAmB,UAAvC;AACD;;;;gCAEO,E,EAAW;AACjB,iBAAK,QAAL,GAAgB,EAAhB;AACA,mBAAO,IAAP;AACD;;;+BAKG;AACF,mBAAO,KAAK,OAAL,IAAgB,KAAK,KAAL,CAAW,MAAlC;AACD;;;8BAKE;AACD,gBAAI,KAAK,IAAL,EAAJ,EAAiB;AACf,sBAAM,IAAI,KAAJ,CAAU,mBAAV,CAAN;AACD;AAED,mBAAO,CAAC,KAAK,IAAL,EAAR,EAAqB;AACnB,oBAAM,QAAQ,KAAK,KAAL,EAAd;AACA,oBAAI,KAAJ,EAAW;AACT,wBAAM,SAAS,KAAK,QAAL,CAAc,KAAd,EAAqB,KAAK,UAA1B,CAAf;AACA,wBAAI,MAAJ,EAAY;AAAE,+BAAO,MAAP;AAAe;AAC9B;AACF;AACD,gBAAM,WAAkB,CAAC,KAAD,EAAQ,KAAR,CAAxB;AACA,gBAAM,WAAW,KAAK,QAAL,CAAc,QAAd,EAAwB,IAAxB,CAAjB;AACA,mBAAO,YAAY,IAAnB;AACD;;;mCAKO;AACN,gDAAW,IAAX;AACD;;;gCAKY;AACX,gBAAI,KAAK,OAAL,CAAa,MAAjB,EAAyB;AAAE,uBAAO,KAAK,OAAL,CAAa,GAAb,EAAP;AAA2B;AAGtD,mBAAM,KAAK,OAAL,GAAe,KAAK,KAAL,CAAW,MAAhC,EAAwC;AACtC,oBAAM,QAAQ,KAAK,KAAL,CAAW,KAAX,CAAiB,KAAK,OAAtB,CAAd;AACA,oBAAM,MAAM,KAAK,MAAL,CAAY,MAAxB;;AAFsC,oCAIhB,KAAK,YAAL,CAAkB,KAAlB,CAJgB;AAAA;AAAA,oBAI/B,IAJ+B;AAAA,oBAIzB,KAJyB;;AAMtC,oBAAI,KAAJ,EAAW;AACT,yBAAK,UAAL,GAAkB,KAAlB;AACA,wBAAI,CAAC,KAAK,YAAL,CAAkB,IAAlB,EAAwB,KAAxB,EAA+B,KAA/B,CAAL,EAA4C;AAC1C,+BAAO,IAAP;AACD;AACF,iBALD,MAKO;AACL,yBAAK,YAAL,CAAkB,KAAlB;AACD;AACF;AACF;;;+BAKG;AAAA;;AACF,mBAAO;AACL,sBAAM;AAAA,2BAAO;AACX,8BAAM,MAAK,IAAL,EADK,EACQ,OAAO,CAAC,MAAK,IAAL,EAAD,IAAgB,MAAK,GAAL;AAD/B,qBAAP;AAAA;AADD,aAAP;AAKD;;aAKA,OAAO,Q;gCAAS;AAAK,mBAAO,KAAK,IAAL,EAAP;AAAoB;;;qCAKrB,K,EAAa;AAChC,gBAAM,MAAM,KAAK,MAAL,CAAY,MAAxB;AAEA,iBAAK,IAAI,IAAI,CAAb,EAAgB,IAAI,GAApB,EAAyB,GAAzB,EAA8B;AAC5B,oBAAM,OAAO,KAAK,MAAL,CAAY,CAAZ,CAAb;AACA,oBAAM,QAAQ,KAAK,CAAL,EAAQ,IAAR,CAAa,KAAb,CAAd;AACA,oBAAI,KAAJ,EAAW;AAAE,2BAAO,CAAC,IAAD,EAAO,KAAP,CAAP;AAAsB;AACpC;AACD,mBAAO,CAAC,IAAD,EAAO,IAAP,CAAP;AACD;;;qCAKoB,I,EAAY,K,EAAc,K,EAAa;AAC1D,gBAAM,SAAS,EAAf;AACA,gBAAM,YAAY,KAAK,CAAL,CAAlB;AAEA,gBAAI,OAAO,SAAP,KAAqB,QAAzB,EAAmC;AACjC,uBAAO,IAAP,CAAY,CAAC,SAAD,EAAY,MAAM,CAAN,KAAY,IAAZ,GAAmB,MAAM,CAAN,CAAnB,GAA8B,MAAM,CAAN,CAA1C,CAAZ;AACA,qBAAK,OAAL,IAAgB,MAAM,CAAN,EAAS,MAAzB;AACD,aAHD,MAKK,IAAI,OAAO,SAAP,KAAqB,QAAzB,EAAmC;AACtC,oBAAM,QAAQ,MAAM,SAAN,CAAd;AACA,uBAAO,IAAP,CAAY,CAAC,MAAM,iBAAN,EAAD,EAA4B,KAA5B,CAAZ;AACA,qBAAK,OAAL,IAAgB,MAAM,CAAN,EAAS,MAAzB;AACD,aAJI,MAMA,IAAI,OAAO,SAAP,KAAqB,UAAzB,EAAqC;AACxC,oBAAM,MAAM,UAAU,IAAV,CAAe,IAAf,EAAqB,KAArB,EAA4B,MAA5B,EAAoC,KAApC,CAAZ;AACA,oBAAM,OAAO,MAAM,CAAN,EAAS,MAAtB;AACA,qBAAK,OAAL,IAAgB,OAAO,GAAP,KAAe,QAAf,GACX,KAAK,KAAL,CAAW,KAAK,GAAL,CAAS,GAAT,CAAX,KAA6B,IADlB,GAC0B,IAD1C;AAED,aALI,MAOA,IAAI,aAAa,IAAjB,EAAuB;AAC1B,qBAAK,OAAL,IAAgB,MAAM,CAAN,EAAS,MAAzB;AAEA,uBAAO,KAAP;AACD;AAGD,iBAAK,OAAL,GAAe,KAAK,OAAL,CAAa,MAAb,CAAoB,OAAO,OAAP,EAApB,CAAf;AAGA,mBAAO,OAAO,MAAP,GAAgB,IAAhB,GAAuB,KAA9B;AACD;;;qCAKoB,K,EAAa;AAChC,oBAAO,KAAK,YAAZ;AACE,qBAAK,OAAL;AAAc,0BAAM,IAAI,KAAJ,CAAU,KAAK,YAAL,CAAkB,KAAlB,CAAV,CAAN;AACd,qBAAK,QAAL;AAAe,yBAAK,OAAL,IAAgB,CAAhB;AAAmB;AAClC;AAAS,yBAAK,aAAL,CAAmB,KAAnB;AAHX;AAKD;;;sCAKqB,K,EAAa;AACjC,gBAAM,OAAO,MAAM,KAAN,CAAY,CAAZ,EAAe,CAAf,CAAb;AACA,iBAAK,OAAL,CAAa,IAAb,CAAkB,CAAC,KAAK,iBAAL,EAAD,EAA2B,IAA3B,CAAlB;AACA,iBAAK,OAAL,IAAgB,CAAhB;AACD;;;qCAKoB,K,EAAa;AAChC,mBAAO,eAAa,KAAK,WAAL,EAAb,8CAEA,MAAM,OAAN,CAAc,MAAd,EAAsB,GAAtB,EAA2B,KAA3B,CAAiC,CAAjC,EAAoC,EAApC,CAFA,UAAP;AAGD;;;sCAKkB;AACjB,gBAAM,QAAQ,KAAK,KAAL,CAAW,KAAX,CAAiB,CAAjB,EAAoB,KAAK,OAAzB,EAAkC,KAAlC,CAAwC,IAAxC,CAAd;AACA,gBAAM,MAAM,MAAM,MAAM,MAAN,GAAe,CAArB,EAAwB,MAAxB,GAAiC,CAA7C;AACA,mBAAU,MAAM,MAAhB,SAA0B,GAA1B;AACD","file":"./tinylex.js","sourcesContent":["(function webpackUniversalModuleDefinition(root, factory) {\n\tif(typeof exports === 'object' && typeof module === 'object')\n\t\tmodule.exports = factory();\n\telse if(typeof define === 'function' && define.amd)\n\t\tdefine([], factory);\n\telse {\n\t\tvar a = factory();\n\t\tfor(var i in a) (typeof exports === 'object' ? exports : root)[i] = a[i];\n\t}\n})(typeof self !== 'undefined' ? self : this, function() {\nreturn \n\n\n// WEBPACK FOOTER //\n// webpack/universalModuleDefinition"," \t// The module cache\n \tvar installedModules = {};\n\n \t// The require function\n \tfunction __webpack_require__(moduleId) {\n\n \t\t// Check if module is in cache\n \t\tif(installedModules[moduleId]) {\n \t\t\treturn installedModules[moduleId].exports;\n \t\t}\n \t\t// Create a new module (and put it into the cache)\n \t\tvar module = installedModules[moduleId] = {\n \t\t\ti: moduleId,\n \t\t\tl: false,\n \t\t\texports: {}\n \t\t};\n\n \t\t// Execute the module function\n \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n \t\t// Flag the module as loaded\n \t\tmodule.l = true;\n\n \t\t// Return the exports of the module\n \t\treturn module.exports;\n \t}\n\n\n \t// expose the modules object (__webpack_modules__)\n \t__webpack_require__.m = modules;\n\n \t// expose the module cache\n \t__webpack_require__.c = installedModules;\n\n \t// define getter function for harmony exports\n \t__webpack_require__.d = function(exports, name, getter) {\n \t\tif(!__webpack_require__.o(exports, name)) {\n \t\t\tObject.defineProperty(exports, name, {\n \t\t\t\tconfigurable: false,\n \t\t\t\tenumerable: true,\n \t\t\t\tget: getter\n \t\t\t});\n \t\t}\n \t};\n\n \t// getDefaultExport function for compatibility with non-harmony modules\n \t__webpack_require__.n = function(module) {\n \t\tvar getter = module && module.__esModule ?\n \t\t\tfunction getDefault() { return module['default']; } :\n \t\t\tfunction getModuleExports() { return module; };\n \t\t__webpack_require__.d(getter, 'a', getter);\n \t\treturn getter;\n \t};\n\n \t// Object.prototype.hasOwnProperty.call\n \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n\n \t// __webpack_public_path__\n \t__webpack_require__.p = \"\";\n\n \t// Load entry module and return exports\n \treturn __webpack_require__(__webpack_require__.s = 0);\n\n\n\n// WEBPACK FOOTER //\n// webpack/bootstrap 8e785c4a7410adb20419","export type Match = RegExpExecArray\nexport type Token = [string, string]\nexport type RuleFn = (match: Match, tokens: Token[], chunk: string) => number|void\nexport type Rule = [RegExp, string|number|RuleFn]|[RegExp]\nexport type RuleMatch = [Rule, Match]\nexport type Ruleset = Rule[]\nexport type OnToken = (token: Token, match: Match) => Token|string\nexport type ErrorAction = 'throw'|'tokenize'|'ignore'\n\nexport interface Options {\n  onError: ErrorAction\n}\n\nconst opts: Options = {\n  onError: 'tokenize'\n}\n\nexport class TinyLex {\n  private _code: string\n  private _rules: Rule[]\n  private _options: Options\n  private _cursor: number\n  private _tokens: Token[]\n  private _onToken: OnToken\n  private _lastMatch: Match\n  private _errorAction: ErrorAction\n\n  constructor(code: string, rules: Ruleset, options: Options = opts) {\n    this._code = code || ''\n    this._rules = rules || []\n    this._cursor = 0\n    this._tokens = []\n    this._onToken = (token) => { return token }\n    this._errorAction = options.onError || 'tokenize'\n  }\n\n  onToken(fn: OnToken): this {\n    this._onToken = fn\n    return this\n  }\n\n  /**\n   * Return true if the lexer is consumed.\n   */\n  done(): boolean {\n    return this._cursor >= this._code.length\n  }\n\n  /**\n   * Return a single lexer match or eof.\n   */\n  lex(): Token|string {\n    if (this.done()) {\n      throw new Error('lexer is consumed')\n    }\n\n    while (!this.done()) {\n      const token = this._scan()\n      if (token) {\n        const _token = this._onToken(token, this._lastMatch)\n        if (_token) { return _token }\n      }\n    }\n    const eofToken: Token = ['EOF', 'EOF']\n    const newToken = this._onToken(eofToken, null)\n    return newToken || null\n  }\n\n  /**\n   * Consume the lexer and return a list of its tokens.\n   */\n  tokenize(): (Token|string)[] {\n    return [...this]\n  }\n\n  /**\n   * Lexer scan method.\n   */\n  private _scan(): Token {\n    if (this._tokens.length) { return this._tokens.pop() }\n    // Process input while there aren't any tokens and we\n    // haven't reached the end.\n    while(this._cursor < this._code.length) {\n      const chunk = this._code.slice(this._cursor)\n      const len = this._rules.length\n\n      const [rule, match] = this._testRuleSet(chunk)\n\n      if (match) {\n        this._lastMatch = match\n        if (!this._handleMatch(rule, match, chunk)) {\n          return null\n        }\n      } else {\n        this._handleError(chunk)\n      }\n    }\n  }\n\n  /**\n   * Javascript iterator method.\n   */\n  next() {\n    return {\n      next: () => ({\n        done: this.done(), value: !this.done() && this.lex()\n      })\n    }\n  }\n\n  /**\n   * Javascript iterable protocol.\n   */\n  [Symbol.iterator]() { return this.next() }\n\n  /**\n   * Iterate the ruleset and return a match if found.\n   */\n  private _testRuleSet(chunk: string): RuleMatch {\n    const len = this._rules.length\n    // Process rules in order to find a match.\n    for (let i = 0; i < len; i++) {\n      const rule = this._rules[i]\n      const match = rule[0].exec(chunk)\n      if (match) { return [rule, match] }\n    }\n    return [null, null]\n  }\n\n  /**\n   * Handle a lexer match.\n   */\n  private _handleMatch(rule: Rule, match: Match, chunk: string): boolean {\n    const tokens = []\n    const specifier = rule[1]\n\n    if (typeof specifier === 'string') {\n      tokens.push([specifier, match[1] != null ? match[1] : match[0]])\n      this._cursor += match[0].length\n    }\n\n    else if (typeof specifier === 'number') {\n      const value = match[specifier]\n      tokens.push([value.toLocaleUpperCase(), value])\n      this._cursor += match[0].length\n    }\n\n    else if (typeof specifier === 'function') {\n      const num = specifier.call(this, match, tokens, chunk)\n      const size = match[0].length\n      this._cursor += typeof num === 'number'\n        ? (Math.floor(Math.abs(num)) || size) : size\n    }\n\n    else if (specifier == null) {\n      this._cursor += match[0].length\n      // A token was not added.\n      return false\n    }\n\n    // Reverse before concatenation because values are popped.\n    this._tokens = this._tokens.concat(tokens.reverse())\n\n    // A token may have been added.\n    return tokens.length ? true : false\n  }\n\n  /**\n   * Handle a lex error (no rule found).\n   */\n  private _handleError(chunk: string) {\n    switch(this._errorAction) {\n      case 'throw': throw new Error(this._getErrorStr(chunk))\n      case 'ignore': this._cursor += 1; break\n      default: this._tokenizeChar(chunk)\n    }\n  }\n\n  /**\n   * Tokenize the next single character in the current chunk.\n   */\n  private _tokenizeChar(chunk: string): void {\n    const char = chunk.slice(0, 1)\n    this._tokens.push([char.toLocaleUpperCase(), char])\n    this._cursor += 1\n  }\n\n  /**\n   * Get a lex error message.\n   */\n  private _getErrorStr(chunk: string): string {\n    return `lex error:${this._lineAndCol()}`\n    + `\\n  match not found for chunk:`\n    + ` \"${chunk.replace(/\\s+/g, ' ').slice(0, 32)}...\"`\n  }\n\n  /**\n   * Return the current line and column based on the lexer progress.\n   */\n  private _lineAndCol(): string {\n    const lines = this._code.slice(0, this._cursor).split('\\n')\n    const col = lines[lines.length - 1].length + 1\n    return `${lines.length}:${col}`\n  }\n}\n\n\n\n// WEBPACK FOOTER //\n// ./tinylex.ts"],"sourceRoot":""}