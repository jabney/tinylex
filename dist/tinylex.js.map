{"version":3,"sources":["webpack:///webpack/universalModuleDefinition","webpack:///webpack/bootstrap 5898dc54ef20cda001a7","webpack:///./tinylex.ts"],"names":[],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD,O;ACVA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;;AAGA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAK;AACL;AACA;;AAEA;AACA;AACA;AACA,mCAA2B,0BAA0B,EAAE;AACvD,yCAAiC,eAAe;AAChD;AACA;AACA;;AAEA;AACA,8DAAsD,+DAA+D;;AAErH;AACA;;AAEA;AACA;;;;;;;;;;;;;;;;;;;;;;AClDA,IAAU;AACO,qBAGX;AAJgB;;;AAWpB,qBAAwB,MAAgB;YAAE,8EAAuB;;;;AAC5D,YAAE,CAAM,MAAQ,QAAS,QAAE;AAC5B,kBAAM,IAAS,MAEjB;AAAC;AACG,aAAM,QAAO;AACb,aAAO,SAAQ;AACf,aAAS,WAAU;AACnB,aAAO,SAAI;AACX,aAAQ,UACd;AAKI;;;;;AACF,gBAAW,QAAG,CAAK,KAAM,SAAQ,KAAO,UAAQ,KAAM,MAAO;AAC1D,gBAAO,OAAE;AAAK,qBAAY;AAAC;AACxB,mBACR;AAKG;;;;AACD,mBAAM,CAAK,KAAO,QAAG;AACnB,oBAAW,QAAO,KAAQ;AACvB,oBAAO,OAAE;AAAO,2BAAO;AAC5B;AAAC;AACK,mBAAC,CAAM,OACf;AAKa;;;;AAGX,mBAAM,CAAK,KAAQ,QAAO,UAAQ,KAAO,SAAO,KAAM,MAAO;AAC3D,oBAAW,QAAO,KAAM,MAAM,MAAK,KAAQ;AAC3C,oBAAS,MAAO,KAAO,OAEjB;;AAJwD,oCAIpC,KAAa,aAAO;;oBAAnC;oBAAQ;;AAEhB,oBAAO,OAAE;AACP,wBAAC,CAAK,KAAe,eAAK,MAAO,OAAS,QAAE;AACvC,+BACR;AACF;AAAM,uBAAE;AACH,wBAAK,KAAS,SAAiB,iBAAE;AAClC,8BAAM,IAAS,MAAC,eAAiB,KAE7B,4DAAU,MAAQ,QAAO,QAAM,KAAM,MAAE,GAC7C;AAAM,2BAAE;AACN,4BAAU,OAAQ,MAAM,MAAE,GAAI;AAC1B,6BAAQ,QAAK,KAAC,CAAK,KAAoB,qBAAQ;AAC/C,6BAAO,UACb;AACF;AACF;AAAC;AAEE,gBAAK,KAAQ,QAAQ,QAAE;AAClB,uBAAK,KAAQ,QACrB;AACF;AAKQ;;;;AACE,gDACV;AAKI;;;;;;AACI;AACA;AAAQ;AACN,8BAAM,MAAO,QAAO,OAAE,CAAK,MAAO,UAAQ,MAGpD;AAJiB;;AADR;AAUT;;aAAO,OAAU;;AAAW,mBAAK,KAAQ;AAKrB;;;qCAAc;AAChC,gBAAS,MAAO,KAAO,OAAO;AAE1B,iBAAC,IAAK,IAAI,GAAG,IAAM,KAAK,KAAG;AAC7B,oBAAU,OAAO,KAAO,OAAG;AAC3B,oBAAW,QAAO,KAAG,GAAK,KAAO;AAC9B,oBAAO,OAAE;AAAO,2BAAC,CAAK,MAAS;AACpC;AAAC;AACK,mBAAC,CAAK,MACd;AAKsB;;;uCAAW,MAAc,OAAe;AAC5D,gBAAY,SAAK;AACjB,gBAAe,YAAO,KAAG;AAEtB,gBAAC,OAAgB,cAAc,UAAE;AAC5B,uBAAK,KAAC,CAAU,WAAO,MAAG,MAAU,OAAM,MAAK,KAAM,MAAK;AAC5D,qBAAO,UAAS,MAAG,GACzB;AAEI,uBAAK,OAAgB,cAAc,UAAE;AACvC,oBAAW,QAAQ,MAAW;AACxB,uBAAK,KAAC,CAAM,MAAoB,qBAAS;AAC3C,qBAAO,UAAS,MAAG,GACzB;AAEI,aANI,UAMC,OAAgB,cAAgB,YAAE;AACzC,oBAAS,MAAY,UAAM,OAAQ,QAAQ;AAC3C,oBAAU,OAAQ,MAAG,GAAO;AACxB,qBAAO,UAAI,OAAU,QACrB,WAAK,KAAM,MAAK,KAAI,IAAM,SAAW,OAC3C;AAEI,aAPI,MAOA,IAAU,aAAS,MAAE;AACvB,qBAAO,UAAS,MAAG,GAAO;AAExB,uBACR;AAAC;AAEG,iBAAQ,UAAO,KAAQ,QAAO,OAAO,OAAW;AAG9C,mBAAO,OAAS,SAAO,OAC/B;AAKoB;;;;AAClB,gBAAW,QAAO,KAAM,MAAM,MAAE,GAAM,KAAQ,QACtC,MAAM;AACR,mBAAM,MACd;AAKgB;;;;AACV,iBAAM,QAAO,KAAO,SAAO,KAAQ,UACzC;AACD","file":"./tinylex.js","sourcesContent":["(function webpackUniversalModuleDefinition(root, factory) {\n\tif(typeof exports === 'object' && typeof module === 'object')\n\t\tmodule.exports = factory();\n\telse if(typeof define === 'function' && define.amd)\n\t\tdefine([], factory);\n\telse if(typeof exports === 'object')\n\t\texports[\"TinyLex\"] = factory();\n\telse\n\t\troot[\"TinyLex\"] = factory();\n})(typeof self !== 'undefined' ? self : this, function() {\nreturn \n\n\n// WEBPACK FOOTER //\n// webpack/universalModuleDefinition"," \t// The module cache\n \tvar installedModules = {};\n\n \t// The require function\n \tfunction __webpack_require__(moduleId) {\n\n \t\t// Check if module is in cache\n \t\tif(installedModules[moduleId]) {\n \t\t\treturn installedModules[moduleId].exports;\n \t\t}\n \t\t// Create a new module (and put it into the cache)\n \t\tvar module = installedModules[moduleId] = {\n \t\t\ti: moduleId,\n \t\t\tl: false,\n \t\t\texports: {}\n \t\t};\n\n \t\t// Execute the module function\n \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n \t\t// Flag the module as loaded\n \t\tmodule.l = true;\n\n \t\t// Return the exports of the module\n \t\treturn module.exports;\n \t}\n\n\n \t// expose the modules object (__webpack_modules__)\n \t__webpack_require__.m = modules;\n\n \t// expose the module cache\n \t__webpack_require__.c = installedModules;\n\n \t// define getter function for harmony exports\n \t__webpack_require__.d = function(exports, name, getter) {\n \t\tif(!__webpack_require__.o(exports, name)) {\n \t\t\tObject.defineProperty(exports, name, {\n \t\t\t\tconfigurable: false,\n \t\t\t\tenumerable: true,\n \t\t\t\tget: getter\n \t\t\t});\n \t\t}\n \t};\n\n \t// getDefaultExport function for compatibility with non-harmony modules\n \t__webpack_require__.n = function(module) {\n \t\tvar getter = module && module.__esModule ?\n \t\t\tfunction getDefault() { return module['default']; } :\n \t\t\tfunction getModuleExports() { return module; };\n \t\t__webpack_require__.d(getter, 'a', getter);\n \t\treturn getter;\n \t};\n\n \t// Object.prototype.hasOwnProperty.call\n \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n\n \t// __webpack_public_path__\n \t__webpack_require__.p = \"\";\n\n \t// Load entry module and return exports\n \treturn __webpack_require__(__webpack_require__.s = 0);\n\n\n\n// WEBPACK FOOTER //\n// webpack/bootstrap 5898dc54ef20cda001a7","export type Match = RegExpExecArray\nexport type Token = [string, string]\nexport type RuleFn = (match, tokens, chunk: string) => number|void\nexport type Rule = [RegExp, string|number|RuleFn]|[RegExp]\nexport type RuleMatch = [Rule, Match]\nexport type Ruleset = Rule[]\n\nexport interface Options {\n  throwOnMismatch: boolean\n}\n\nconst opts: Options = {\n  throwOnMismatch: false\n}\n\nexport class TinyLex {\n  private _code: string\n  private _rules: Rule[]\n  private _options: Options\n  private _start: number\n  private _tokens: Token[]\n\n  constructor(code: string, rules: Ruleset, options: Options = opts) {\n    if (!(Array.isArray(rules))) {\n      throw new Error(\n        'Invalid ruleset: rules must be a non-zero length array')\n    }\n    this._code = code\n    this._rules = rules\n    this._options = options\n    this._start = 0\n    this._tokens = []\n  }\n\n  /**\n   * Return true if the lexer is consumed.\n   */\n  done(): boolean {\n    const _done = !this._code || this._start >= this._code.length\n    if (_done) { this._destroy() }\n    return _done\n  }\n\n  /**\n   * Return a single lexer match or eof.\n   */\n  lex(): Token {\n    while(!this.done()) {\n      const token = this._scan()\n      if (token) { return token }\n    }\n    return ['EOF', 'EOF']\n  }\n\n  /**\n   * Lexer scan method.\n   */\n  private _scan(): Token {\n    // Process input while there aren't any tokens and we\n    // haven't reached the end.\n    while(!this._tokens.length && this._start < this._code.length) {\n      const chunk = this._code.slice(this._start)\n      const len = this._rules.length\n\n      const [rule, match] = this._testRuleSet(chunk)\n\n      if (match) {\n        if (!this._handleMatches(rule, match, chunk)) {\n          return null\n        }\n      } else {\n        if (this._options.throwOnMismatch) {\n          throw new Error(`lex error:${this._currentLine()}`\n            + `\\n  match not found for chunk:`\n            + ` \"${chunk.replace(/\\s+/g, ' ').slice(0, 32)}...\"`)\n        } else {\n          const char = chunk.slice(0, 1)\n          this._tokens.push([char.toLocaleUpperCase(), char])\n          this._start += 1\n        }\n      }\n    }\n\n    if (this._tokens.length) {\n      return this._tokens.pop()\n    }\n  }\n\n  /**\n   * Consume the lexer and return a list of its tokens.\n   */\n  tokenize(): Token[] {\n    return [...this]\n  }\n\n  /**\n   * Javascript iterator method.\n   */\n  next() {\n    return {\n      next: () => ({\n        done: this.done(), value: !this.done() && this.lex()\n      })\n    }\n  }\n\n  /**\n   * Javascript iterable protocol.\n   */\n  [Symbol.iterator]() { return this.next() }\n\n  /**\n   * Iterate the ruleset and return a match if found.\n   */\n  private _testRuleSet(chunk: string): RuleMatch {\n    const len = this._rules.length\n    // Process rules in order to find a match.\n    for (let i = 0; i < len; i++) {\n      const rule = this._rules[i]\n      const match = rule[0].exec(chunk)\n      if (match) { return [rule, match] }\n    }\n    return [null, null]\n  }\n\n  /**\n   * Handle a lexer match.\n   */\n  private _handleMatches(rule: Rule, match: Match, chunk: string): boolean {\n    const tokens = []\n    const specifier = rule[1]\n\n    if (typeof specifier === 'string') {\n      tokens.push([specifier, match[1] != null ? match[1] : match[0]])\n      this._start += match[0].length\n    }\n\n    else if (typeof specifier === 'number') {\n      const value = match[specifier]\n      tokens.push([value.toLocaleUpperCase(), value])\n      this._start += match[0].length\n    }\n\n    else if (typeof specifier === 'function') {\n      const num = specifier(match, tokens, chunk)\n      const size = match[0].length\n      this._start += typeof num === 'number'\n        ? (Math.floor(Math.abs(num)) || size) : size\n    }\n\n    else if (specifier == null) {\n      this._start += match[0].length\n      // A token was not added.\n      return false\n    }\n\n    this._tokens = this._tokens.concat(tokens.reverse())\n\n    // A token may have been added.\n    return tokens.length ? true : false\n  }\n\n  /**\n   * Return the current line number based on the lexer progress.\n   */\n  private _currentLine(): number {\n    const lines = this._code.slice(0, this._start)\n      .split('\\n')\n    return lines.length\n  }\n\n  /**\n   * Clear member variable referneces.\n   */\n  private _destroy(): void {\n    this._code = this._rules = this._tokens = null\n  }\n}\n\n\n\n// WEBPACK FOOTER //\n// ./tinylex.ts"],"sourceRoot":""}